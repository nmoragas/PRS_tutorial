---
title: "Polygenic Risk Score (PRS) Tutorial"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  rmdformats::readthedown
css: style.css
---


![](figures/0_mcc_logo.png)

<style>
body {
text-align: justify}
</style>

# OVERVIEW 

The purpose of this tutorial is to furnish a step-by-step guide on the execution of a Polygenic Risk Score (PRS) analysis, accompanied by an introduction to fundamental genetic principles germane to this methodology.

The tutorial is divided into two sections, First, a series of basic concepts about genetics and PRS are introduced at a theoretical level. Secondly, the tutorial itself consists of 6 steps which are detailed below.

**Step-by-step PRS analysis:**

0. [STEP 0: Data selection + QC check](#step0)
1. [STEP 1: SNPs Extraction](#step1)
2. [STEP 2: SNPs Alignament check](#step2)
3. [STEP 3: Quality control (QC)](#step3)
4. [STEP 4: PRS calculation](#step4)
5. [STEP 5: PRS resultsn](#step5)



## Software requirements


- **Linux terminal** access with the following tools installed:
    - **PLINK 2** - https://www.cog-genomics.org/plink/2.0/ 
    - **bcftools** - http://www.htslib.org/download/ 
<br>    
- **R** 

### - R Library

R packages required:

<div class="console_R"> R
```{r message=FALSE, warning=FALSE}
library(readxl)
library(data.table)
library(dplyr)
library(ggplot2)
```
</div>
<br>


## Required Data

To carry out this PRS analysis it is necessary two types of data. Here is the link to download the data used in the tutorial. If you want to use your own data, see what is necessary in the section [STEP 0 - Data selection + QC check](#step0).

  - **SNPs DATA**. 
    List of SNPs associated with a characteristic of interest. This tutorial will use a list of 205 SNPs associated with colon cancer (CRC) from the article: [Deciphering colorectal cancer genetics through multi-omic analysis of 100,204 cases and 154,587 controls of European and east Asian ancestries](https://www.nature.com/articles/s41588-022-01222-9)
    
   You can download it directly here: [**Download - 1_CRC_SNPs_list_205_Nature_2023**](https://github.com/nmoragas/PRS_tutorial/tree/main/resources)
  
    
<br>

  - **TARGET DATA**. 
  Imputed genotyping data from a population of interest. Simulated data based on GenRisk data will be used here. For reasons of space, only the data of the patients with the SNPs associated with CRC can be downloaded (document obtained in STEP 1) [**Download - GenRisk_all_CRC_SNPs_perm.vcf **](https://github.com/nmoragas/PRS_tutorial/tree/main/resources).
  
  To be used from the section [Step 1 - SNP extraction. 2 VCF files concatenation](#vcf_conca)
  
  - **METADATA**.
  Phenotypic data of the target data. In this case which of the samples is controlled and which CRC. [Metadata_GenRIsk - ](https://github.com/nmoragas/PRS_tutorial/tree/main/resources)


<div class="alert alert-danger">
**Attention**: Whether you wish to utilize your own data or existing datasets, it's important to note that the data used should have already undergone a minimum quality control (QC) process, with hg37 as the reference genome. For the target data, it has been imputed using the 1000 Genomes reference.

For more information regarding the format of the data to be used or how to adapt see [here](#step0)

</div>

# What’s a Polygenic Risk Score

<center>
![](figures/0_plot_prs.png)
</center>
<br>
A Polygenic Risk Score (PRS) is a single numerical metric that estimates an individual's genetic risk for a particular disease or trait (phenotype). This score is calculated by summing the contributions of risk alleles carried by the individual, each weighted by its respective effect size as determined by a Genome-Wide Association Study (GWAS) specific to the phenotype in question. 

<center>
![](figures/0_formula_prs.png)
</center>

In essence, the PRS encapsulates the combined impact of various genetic variants, predominantly Single Nucleotide Polymorphisms (SNPs), within an individual's genome. A higher PRS indicates a greater genetic predisposition, while a lower score suggests a reduced risk, thereby facilitating the prediction of disease susceptibility or trait expression based on one's genetic makeup. This approach offers valuable insights into the genetic architecture of complex traits and diseases.


## Effect size - βi

In PRS, there exist two primary approaches: 

  - **Unweighted PRS**, where each genetic variant is assigned a fixed weight of 1 (βi = 1).
  
  - **Weighted PRS**, which employs the actual effect sizes, typically represented as betas (βi) or Odds Ratios (OR), derived from GWAS specific to the phenotype in question. 
  
The choice between these two approaches is contingent upon several key factors.


**¿When to use an unweighted PRS (βi = 1)?**

  - Your data have been used for the GWAS -> model overfitting 
  - Poorly robust GWAS



## PRS applications

  - Disease risk prediction
  - Screening and prevention. 
  - Personalized treatment 
  - Epidemiological Studies
  - Drug Development 


## Step-by-step PRS analysis

The step-by-step analysis structure that will be followed to perform the PRS analysis is as follows:

![](figures/0_diagram_step_by_step.png)

0. [STEP 0: Data selection + QC check](#step0). The process begins with the careful selection of genetic data (SNPs data and target data) relevant to the study, ensuring that it accomplishes general quality control standards commonly used in GWAS analyses.

1. [STEP 1: SNPs Extraction](#step1). Consists of the extraction of the SNPs associated with the study characteristic or disease from the total pool of SNPs in the target dataset where the PRS will be calculated.

2. [STEP 2: SNPs Alignament check](#step2). Discrepancies, such as missing SNPs, duplicates, variations in strand orientation, and more, can occur between the SNPs in the SNP dataset and the target data. These disparities may arise due to differences in platforms, imputation methods, or genome builds. Therefore, it is essential to carefully evaluate and resolve such differences whenever possible.

3. [STEP 3: Quality control (QC)](#step3). Imputed genotyping data, QC is performed both before and after imputation, ensuring the use of high-quality data and the exclusion of poorly imputed variants. 

4. [STEP 4: PRS calculation](#step4). Calculate the PRS by combining the genetic variants (SNPs) and their associated effect sizes in the target data.

5. [STEP 5: PRS results](#step5). This involves drawing meaningful insights from the calculated scores and making conclusions about genetic predisposition for the studied phenotype.


## Other Basic Genetic Concepts

# STEP 0 - Data selection + QC check{#step0}

Below is detailed where to find, in which formats, what minimum information is required as well as what minimum QC the data must have passed.


## SNPs Data Selection

The initial phase in the analysis of the Polygenic Risk Score (PRS) involves acquiring the base data, which comprises a list of SNPs associated with the specific trait or condition of interest. 

These SNP datasets can be sourced from publicly available GWAS studies found in the literature or various genetic databases. Alternatively, researchers can conduct their own GWAS to generate the required summary statistics.

For the purpose of this tutorial, we will utilize SNP data associated with Colorectal Cancer (CRC) as our reference dataset.

SNPs data are a set of individual SNPs that have been identified as related to the characteristic or trait studied through a GWAS study. These data usually include the position of the SNP in the genome, the estimated genetic effect (such as odds ratio or beta), the allelic frequency, and other related statistics.

<center>
![](figures/step0_snp_data_format.png)
</center>

<br>


### - **Where to find:**

  - Polygenic Score (PGS) Catalog. https://www.pgscatalog.org/ 
  - GWAS Catalog. https://www.ebi.ac.uk/gwas/ 
  - Bibliography  
  - Calculate your own GWAS

<br>

### - **Minimum information required:**

  - Chromosome nº 
  - Position
  - Effect and non-effect allele
  - Effect size (betas or OR)



<br>

### - **QC check:**

It is necessary to ensure that the list of SNPs selected has passed a minimum QC check. -> those applied to a GWAS

  - Genome build -> Check that the reference genome is the same between the SNP data and the target data. Otherwise, it is necessary to carry out a **Liftover**. Better perform on the data of the SNPs of interest.
  - Effect allele
  - Standard GWAS QC:
      - Genotyping rate >0,99
      - Remove SNPs with >5% missing data
      - Heterozygosity. Remove samples >  mean(proportion of heterozygous sites ) ± 3 * sd(proportion of heterozygous sites) 
      - Exclude individuals with sex discordance
      - Imputation information score (INFO score). > 0.3 – 0.8
      - Minor Allele Frequency (MAF). > 0.005 – 0,001
      - Linkage-disequilibrium (LD) score  
      - Hardy-Weinberg equilibrium (HWE) P>1x10-6
      

## Target Data


TARGET DATA means the genotyping data of a population already imputed. (Usually own data - collaborations)

<center>
![](figures/0_target_data.png)
</center>

This data can be in multiple formats some of the most common are detailed below. (Depending on where they are downloaded or with which the charge is made).

### - **Imputed genotype data formats:**

  - **Variant Call Format (VCF)**. e.g chr.{i}vcf.gz 
  - **PLINK 1.9 format** [.bed] [.bim] [.fam]
  - **BGEN format** [.bgen], [.sample], [.bgen.bgi]
  - **PLINK 2 format** [.pgen], [.pvar], [.psam]


<div class="note">
**NOTE:** Generally, imputation with 1000 genomes or TopMed results in vcf files separated by chromosomes. This tutorial starts with data in this format.
</div>


### - **QC check:**

  - More than 100 individuals
  - Genome build 
  - No sample overlap with SNPs GWAS samples
  - Standard GWAS
    For samples:
      - Individuals genotype rate >0.99
      - Remove sample with >10% missing data
      - Heterozygosity. Remove samples >  mean(proportion of heterozygous sites ) ± 3 * sd(proportion of heterozygous sites) 
      - Exclude individuals with sex discordance
      - Remove duplicates and relatedness samples. PI_HAT > 0.8
    For SNPs:
      - Imputation information score (INFO score). > 0.3 – 0.8
      - Minor Allele Frequency (MAF). > 0.01 - 0.005
      - Linkage-disequilibrium (LD) score  
      - Hardy-Weinberg Equilibrium (HWE) p > 1x10-6

<div class="alert alert-danger">
**ATTENTION!** The quality control for this data is conducted both before and after imputation. Post-imputation quality control (QC) related to SNPs can be carried out either before initiating the Polygenic Risk Score (PRS) analysis or during the analysis. In this instance, SNP QC is performed after extracting the SNPs of interest from the Target Data. This approach is chosen because the dataset is smaller, making the process faster. 
</div>


# STEP 1 - SNPs Extraction{#step1}

This section consists of two parts:

  - [SNPs list preparation](#snp_list)
  - [SNPs extraction](#snp_extraction)
  
## SNPs list preparation{#snp_list}

Preparation of a list of SNPs associated with CRC for extraction in the target data. A .txt file with two columns: 

  - **Chromosome number**
  - **SNP position**
  
<center>
![Example .txt file with the identifiers of the SNPs of interest.](figures/1_snp_txt_list.png)
</center>

<br>

<div class="alert alert-danger">
**ATTENTION!** If the reference genome does not match the list of SNPs associated with the study trait and the target data to be used, a Liftover must be performed, see [here](liftover).

In this case both the list of SNPs and the target date are in GRCh37.

</div>


### - Load SNPs associated to CCR:

SNPs Data from Ceres Fernandez-Rozadilla et al. Nature 2023, save as: **.data/resources/1_CRC_SNPs_list_205_Nature_2023.xlsx**

<div class="console_R"> R
```{r include=FALSE}
# set directory
#setwd("./practical")
setwd("/mnt/hydra/ubs/shared/users/Nuria/courses/PRS_course_NM/practical")
```
```{r eval=FALSE}
# load data
CRC_SNP <- read_excel("data/resources/1_CRC_SNPs_list_205_Nature_2023.xlsx")

# The first 5 rows and first 7 columns are shown
CRC_SNP[c(1:5),c(1:7)]
```
</div>

<br>
```{r echo=FALSE}
CRC_SNP <- read_excel("data/resources/1_CRC_SNPs_list_205_Nature_2023.xlsx")
knitr::kable(CRC_SNP[c(1:5),c(1:7)])
```

<br>


### - Cration of chr position .txt file 

The CHR and POS columns (GRCh37) are saved in a .txt file.

<div class="console_R"> R
```{r eval=FALSE}
# .txt file generation
SNP_file_CRC <- CRC_SNP[,c(1,2)]
head(SNP_file_CRC)
```
</div>
<br>
```{r echo=FALSE}
SNP_file_CRC <- CRC_SNP[,c(1,2)]
knitr::kable(head(SNP_file_CRC))
```

### - Save .txt file
<div class="console_R"> R
```{r eval=FALSE}
# two avoid scientific annotation
SNP_file_CRC$`POS (GRCh37)` <- format(SNP_file_CRC$`POS (GRCh37)`, scientific=FALSE)
# save .txt
write.table(SNP_file_CRC, "data/1_snps_extraction/1_SNP_file_CRC.txt", quote = F, col.names = F, row.names = F, qmethod = "double", sep = "\t")
```
</div>


## SNPs extraction{#snp_extraction}

The aim of this step is to extract data on SNPs associated with colorectal cancer from GenRisk data.

It consists of 3 substeps:

  - [1 SNP Extraction](#snps_extract)
  - [2 VCF files concatenation](#vcf_conca)
  - [3 Conversion to PLINK2 format](#plink_conv)

<center>
![](figures/1_resum_STEP1.png)

</center>



### - GenRisk imputed data

In this case, the GenRisk data already imputed by 1000 genomes will be used. Data imputed with TopMed or 1000Genomes servers return data in **vcf.gz** format:

<center>
![GenRisk Imputed data files:](figures/genrisk_vcf.png)
</center>
<br>
<div class="alert alert-danger">
**ATTENTION!** The data is substantial and cannot be shared. As a solution, the code for extracting CRC SNPs using the Linux bcftools tool, chromosome by chromosome, will be demonstrated without execution. Next, the process of merging individual files from each chromosome will be presented. This final outcome is what will be made available to proceed with the exercise. 

In other words, the data to which you have access are the results of the [VCF files concatenation](#vcf_conca) section and are called: **GenRisk_all_CRC_SNPs.vcf.gz**

On the other hand, the shared data have been modified to ensure compliance with personal data protection regulations.

</div>

```{r include=FALSE}
data_dir <-"/mnt/typhon/data/GenRisk/imputation/GenotypedData/AllData/IMPUTATION/1000G/data/"
vcf_dir <-"/mnt/hydra/ubs/shared/users/Nuria/courses/PRS_course_NM/practical/data/1_snps_extraction"

```

<div class="console_R"> R
```{r eval=FALSE}
# set work directory
setwd("~/practical")

# Determine the directory containing the imputed genotype data.
data_dir <-"~/IMPUTATION/1000G/data/" 
vcf_dir <- "~/data/1_snps_extraction" 
 
```
</div>


### - 1 SNPs extraction:{#snps_extract}

<div class="console_bash"> LINUX Terminal
```{bash eval = FALSE} 
# Directory selection
cd /~/practical

# Extraction of the SNPs in a loop for the different chromosomes. 

## bcftool view <directory/_chr*_vcf.gz> -R <directory/SNP_list.txt> -o <directory/output_file.vcf.gz>
### view -> allows filtering and viewing data contained in VCF files.
### -R -> Region. specific region of the genome
### -o -> Output. 


for i in {1..22}
do
bcftools view .data_dir/GenRisk_chr${i}.vcf.gz -R data/1_snps_extraction/1_SNP_file_CRC.txt -o data/1_snps_extraction/GenRisk_chr${i}_CRC_SNPs.vcf.gz
done


#time 1 min 30 s
```
</div>
<br>

The application of this code generates new vcf files for each chromosome, only with the SNPs present in the file 1_SNP_file_CRC.txt. 
The following **vcf** files are generated:

<center>
![CRC data files](figures/genrisk_vcf_crc.png)
</center>

### - 2 VCF files concatenation:{#vcf_conca}

Merge of GenRisk_chr${i}_CRC_SNPs.vcf.gz into a single file:

<div class="console_R"> R
```{r eval=FALSE}
# Creation of a file concatenation list: 

chromList<-list.files(path = vcf_dir,  pattern="GenRisk_chr*")
write.table(chromList,file= paste0(vcf_dir,"/2_chromList.txt"),quote=FALSE,row.names = FALSE,col.names = FALSE)
```
</div>
<br>

This is the list of files to be concatenated that is created:

<center>
![](figures/1_concat_list.png)
</center>
<br>

<div class="console_bash"> LINUX Terminal
```{bash eval=FALSE}

cd /~/practical

# Concatenation:
bcftools concat -f data/1_snps_extraction/2_chromList.txt -Oz -o data/1_snps_extraction/GenRisk_all_CRC_SNPs_perm.vcf

# time 6s
```
</div>

<br>
<div class="warning">
**GenRisk_all_CRC_SNPs_perm.vcf** is the data that can be downloaded and worked from here.
</div>



<br>
<div class="note">
**NOTE:** The GenRisk_chr${i}_CRC_SNPs.vcf.gz files created during SNP extraction are intermediate, and it is recommended to delete them later to avoid unnecessary space consumption
</div>

<div class="console_bash"> LINUX Terminal
```{bash eval=FALSE}
# Remove the individual chromosome files*

for i in {1..22}
do
  rm GenRisk_chr${i}_CRC_SNPs.vcf.gz
done

```
</div>
<br>

### - 3 Conversion to PLINK2 format{#plink_conv}

Plink2 is a widely utilized tool for genetic data analysis. Converting VCF files to Plink2 enables the utilization of various features, including the creation of genetic relationship matrices and the calculation of polygenic risk scores (PRS). This conversion not only streamlines data compatibility with other tools but also enhances execution speed. Plink2, being equipped with PRS calculation functionality, further facilitates genetic analysis processes.

#### PLINK2 format 

<center>
![](figures/1_plink_format.png)
</center>
 
<br> 
 
#### PLINK2 conversion

Below conversion to PLINK 2 format, relabel variant IDs to ensure they have a unique identifier, and print a frequency report necessary to identify ambidextrous SNPs (SNPs QC, next steps).

Resulting files:
  - PLINK 2 format (.pgen, .pvar, .psam).
  - Obtain allele frequency report (.afreq).

<div class="console_bash"> LINUX Terminal 
```{bash, eval=FALSE}

plink2 --vcf GenRisk_all_CRC_SNPs_perm.vcf \
--new-id-max-allele-len 50 \
--set-all-var-ids @:#_\$r_\$a \
--freq \
--make-pgen \
--out raw_data

```
</div>
<br>

**Code notes:**

  + --vcf -> input file
  + --new-id-max-allele-len 50 -> set the maximum length for new allele identifiers (IDs) in the output format. By default it is 14 and it may not be enough
  + --set-all-var-ids @:#_\$r_\$a \ -> set SNPs id -> chr:pos_ref_alt
  + --freq -> compute allele frequency and output to .afreq file
  + --make-pgen -> generate files in plink 2 format
  
  
<br>

**Results:**
When applying this caddy, 4 files are generated:

  + raw_data.freq
  + raw_data.log
  + raw_data.pgen
  + raw_data.psam
  + raw_data.pvar


<center>
![](figures/1_plink_conversion.png){width=60%}
</center>

<br>

<div class="question">
  <details>
    <summary><strong>**QUESTION 1** </strong> How many variables have been detected? How many samples?
    </summary>
    
    `205` variables and `4295` samples
  </details>
</div>

<br>

# STEP 2 - SNPs Alignament check{#step2}

Inconsistencies, including absent SNPs, duplications, variations in strand orientation, and other discrepancies, may exist between the SNP dataset and the target data. These variations could stem from divergences in platforms, imputation methods, or genome builds. Hence, it is crucial to thoroughly assess and address these distinctions whenever feasible.

These discrepancies can be:

  - [Missing SNPs](#missing)
  - [Multi-allelic / biallelic / Duplicated SNPs](#multi)
  - [Mismatching SNPs](#mismatch)
  - [Ambiguous SNPs](#ambigous)


**Load data**

<div class="console_R"> R
```{r message=FALSE, warning=FALSE}
# re-load original CRC SNPs list.
CRC_SNP <- read_excel("data/resources/1_CRC_SNPs_list_205_Nature_2023.xlsx")

```
</div>
<br>
<div class="console_R"> R
```{r eval=FALSE}
# Load the data of the SNPs extracted from the target data:
pvar<-fread("data/1_snps_extraction/raw_data.pvar")

colnames(pvar)<- c("CHR",	"POS",	"ID"	,"REF",	"ALT",	"FILTER",	"INFO")
head(pvar)
```
</div>
<br>
```{r echo=FALSE}
# load CRC SNPs data
pvar<-fread("data/1_snps_extraction/raw_data.pvar")

colnames(pvar)<- c("CHR",	"POS",	"ID"	,"REF",	"ALT",	"FILTER",	"INFO")
knitr::kable(head(pvar))
```

<br>

## Missing SNPs{#missing}

The selected SNPs may not all be available in the target dataset (Missing SNPs), which could be due to:

  - Different Genotyping / imputation platform
  - SNP have not passed QC (low quality)


![](figures/2_missing.png){width=140%}

Although it looks like all SNPs have been found (205) Let's see if any are missing.


**Find SNPs by chr:position** 

<div class="console_R"> R
```{r}
# Match variant format
CRC_SNP$id_pos <- paste0(CRC_SNP$CHR,":",CRC_SNP$`POS (GRCh37)`)
pvar$id_pos <- paste0(pvar$CHR,":",pvar$POS)


# SNPs not found
snpsNOTpvar<-CRC_SNP[!CRC_SNP$id_pos%in%pvar$id_pos  ,]
```
</div>
<br>

<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> How many variables were found to be missing in our data? Which one?
    </summary>
    <br>
<div class="console_R"> R
```{r eval=FALSE}
snpsNOTpvar
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(snpsNOTpvar)
```
<br>
`1` variable have been identified as missing.
The missing SNP is the one on the X chromosome, as sex chromosome data is not being used.

<br>

<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> What is the problem with the 205 SNPs extracted if we already know that one is missing?     
    </summary>
    <br>
   The problem is that if the missing X chromosome SNP is subtracted from the initial 205 SNPs, theoretically, we would expect to extract 204 SNPs, indicating an extra SNP. There is a duplicated/multi-allelic/bialellic SNP?
  </details>
</div>
<br> 
 
 


## Multi-allelic / Duplicated / Biallelic SNPs{#multi}

<center>
![](figures/2_multi_allel.png){width=60%}

</center>

Let's check if there are any duplicate chr:position IDs:

<div class="console_R"> R
```{r}
table(duplicated(pvar$id_pos))
 
```
</div>

<br>

Yes, there is a duplicated chromosome:position ID. Which one?

<div class="console_R"> R
```{r eval=FALSE}
multi_all <- pvar[duplicated(pvar$POS) | duplicated(pvar$POS, fromLast = TRUE), ]
multi_all
```
</div>
<br>
```{r echo=FALSE}
multi_all <- pvar[duplicated(pvar$POS) | duplicated(pvar$POS, fromLast = TRUE), ]
knitr::kable(multi_all)
```
<br>

To know which one is the incorrect, it must be compared with the original listing.
<br>

<div class="console_R"> R
```{r eval=FALSE}
# the format of the variable ID between tables is equalized. From chr:position_other_allele/effect_allele to chr:position_other_allele_effect_allele
CRC_SNP$ID <- gsub("/","_",CRC_SNP$VARIANT)

#Which is the correct?
id_multi <- multi_all[!multi_all$ID %in% CRC_SNP$ID,] 
id_multi
```
</div>
<br>
```{r echo=FALSE}
CRC_SNP$ID <- gsub("/","_",CRC_SNP$VARIANT)
id_multi <- multi_all[!multi_all$ID %in% CRC_SNP$ID,]
knitr::kable(id_multi)
```
<br>
<div class="console_R"> R
```{r}
#Save the incorrect SNP to delete in the QC step:
## Structure: CHROM  ID      REF     ALT
## ID = chr:pos_REF_ALT

id_multi_to_remove <- id_multi[,c(1,3:5)]
```
```{r eval=FALSE}
write.table(id_multi_to_remove,"data/2_SNPs_alignament_check/multi_to_remove.txt", col.names = F, row.names = F, quote = F)
```
</div>
<br>

This incorrect SNP should be removed from the data. This process is carried out together with the quality control in [STEP 3 - QC](#step3).

<br>


## Mismatching SNPs{#mismatch}

It is essential to verify whether the REF and ALT alleles in the target data match those in the SNP list. For example, in the target data, there may be SNPs with A/C alleles in the base data and G/T alleles in the target data. This discrepancy can occur when one dataset was genotyped with reference to the forward strand, and the other was genotyped with reference to the reverse strand.

SNPs that have mismatched alleles reported in the original SNP list and the target data can be resolved by strand-flipping the alleles to their complementary alleles. Most polygenic scoring software programs perform strand shifting automatically for resolvable SNPs and remove mismatched non-resolvable SNPs.


SNPs with mismatched alleles between the SNP list and the target data can be resolved by "strand-flipping" the alleles to their complementary pairs. Most polygenic scoring software programs automatically perform strand flipping for resolvable SNPs and exclude non-resolvable SNPs with mismatches. 

PLINK2 does not do this automatically, if there is a mismatching SNP in the data, the "strand-flipping" must be done manually.



<center>
![](figures/2_mism.png){width=60%}
</center>

<br>

All SNPs are then verified to have the correct alleles, using ID = chr:position_other_allele_effect_allele.

<div class="console_R"> R
```{r}
## SNPs that have been extracted: 
dim(CRC_SNP[CRC_SNP$ID%in%pvar$ID,])
```
</div>
<br>
<div class="console_R"> R
```{r eval=FALSE}
## SNPs that have not been extracted: 
no_snps <- CRC_SNP[!CRC_SNP$ID%in%pvar$ID,]
no_snps

```
</div>
<br>
```{r echo=FALSE}
no_snps <- CRC_SNP[!CRC_SNP$ID%in%pvar$ID,]
knitr::kable(no_snps)
```
<br>

It has been confirmed that all SNPs have the correct alleles, except for the SNP on the X chromosome

<br>

## Ambiguous SNPs{#ambigous}

Ambiguous (Palindromic) SNPs are those in which the allelic variants are complementary. In the context of PRS calculation, they are SNPs where the two allelic variants are symmetrical (e.g., A/T in the SNP list and T/A in the target data) and have similar frequencies, making it difficult to distinguish which variant is the effective one. If you have access to the effect allele frequency (EAF) data from the list of SNPs of interest, you can compare it with the EAF data in your dataset to determine which allele is the reference (REF). However, EAF data is rarely available in downloadable SNP lists.

In cases where EAF data is not available or when EAF is close to 0.5, these ambiguous SNPs should be excluded. In PRS calculations, SNPs with allelic frequencies close to 0.5 (between 0.4 and 0.6) are considered ambiguous and are typically excluded.

<br>

<center>
![](figures/2_ambig.png){width=60%}
</center>
<br>


<center>
![](figures/2_ambig2.png){width=60%}
</center>
<br>

To check if there are ambiguous SNPs in the data, first load the EAF data from the target data obtained during the extraction of the SNPs and apply an EAF filter >0.4 | <0.6:

<div class="console_R"> R
```{r eval=FALSE}
# load SNPs frequencyes  
freq<-read.table("data/1_snps_extraction/raw_data.afreq",header=F,sep="\t")
colnames(freq)<- c("CHROM",	"ID",	"REF",	"ALT",	"ALT_FREQS",	"OBS_CT")
head(freq)
```
</div>
<br>
```{r echo=FALSE}
# load SNPs frequencyes  
freq<-read.table("data/1_snps_extraction/raw_data.afreq",header=F,sep="\t")
colnames(freq)<- c("CHROM",	"ID",	"REF",	"ALT",	"ALT_FREQS",	"OBS_CT")
knitr::kable(head(freq))
```
<br>

<div class="console_R"> R
```{r}

ambiguous_snps <- freq[freq$ALT_FREQS > 0.4 & freq$ALT_FREQS< 0.6 & 
                        ((freq$REF == "A" & freq$ALT == "T") | 
                         (freq$ALT == "T" & freq$REF == "A") | 
                         (freq$REF == "C" & freq$ALT == "G") | 
                         (freq$ALT == "G" & freq$REF == "C")), ]

```
</div>

<br>

<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> How many ambiguous SNPs were found?
    </summary>
<div class="console_R"> R  
```{r eval=FALSE}
ambiguous_snps
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(ambiguous_snps)
```
<br> 
    There are `3` ambiguous SNPs
</details>
</div>
<br>    
    
Those SNPs are saved to a .txt file to be removed later. 
  
<div class="console_R"> R 
```{r eval=FALSE}
# Save
write.table(ambiguous_snps, "data/2_SNPs_alignament_check/exclrsIDs_ambiguous.txt", sep = "\t", quote = FALSE, row.names = FALSE)
```
</div>
<br> 



# STEP 3 - Quality control (QC){#step3}

It is important to ensure that the SNPs chosen to calculate the PRS present a minimum of quality in the Target data. For this reason, the following points will be reviewed:

- a) [Imputation information score (INFO)](#a_INFO)
- b) [Minor allele frequency (MAF)](#b_minor)
- c) [Linkage Disequilibrium (LD)](#c_LD)
- d) [Hardy-Weinberg Equilibrium (HWE)](#hwe) 

Any SNP that does not pass this QC will be removed in the final step of this section, [Apply QC exclusions](#qc_exclu).

## a) Imputation information score (INFO){#a_INFO}

Imputation is a process used to predict or estimate genotypic information for unobserved or missing genetic variants (SNPs) in a dataset based on available genotype data and reference panels. 

The imputation information (INFO score – r2) statistic is a measure of imputation quality which typically takes values between 0 and 1, where 0 indicates complete uncertainty and 1 represents complete certainty about the imputed genotype.

Variants with a low imputation information score (r^2 < 0.3 - 0.8) are often regarded as less reliable and are typically excluded from further analyses.

In this case a threshold of 0.4 is used.


<div class="console_R"> R 
```{r}
# SNPs target date, already loaded. -> pvar

#pvar<-read.table("data/1_snps_extraction/raw_data.pvar",header=F,sep="\t")
#colnames(pvar)<- c("CHR",	"POS",	"ID"	,"REF",	"ALT",	"FILTER",	"INFO")

```
```{r eval=FALSE}
head(pvar)
```
</div>

<br>
```{r echo=FALSE}
knitr::kable(head(pvar))
```

<br>



In pvar the data about INFO (r^2) is in the column called INFO where there is a lot of other data. R2 is extracted and stored in a new column called R2.

eg. INFO estructure AF=0.63412;MAF=0.36588;**R2=0.94997**;IMPUTED;AC=9067;AN=14206 or AF=0.12046;MAF=0.12046;**R2=0.87593**;IMPUTED;ER2=0.83497;TYPED;AC=1687;AN=14206

The information to be extracted can be seen in bold. 

<br>
<div class="console_R"> R 
```{r}
# Create column R2
pvar$INFO2 <- sub("ER2=.*", "", pvar$INFO)
pvar$R2 <- as.numeric(sub('.*R2=([0-9.]+);.*', '\\1', pvar$INFO2))

```
</div>

<br>

<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> How many SNPs exhibit an imputation value (R²) lower than 0.4? Which are these snps?
    </summary>
    <br>
<div class="console_R"> R    
```{r}
# R2 >0.4
table(pvar$R2 >= 0.4)
```
</div>    
    <br>
  `2` are the SNPs that have a low imputation score and must be eliminated.
  
   <br>
</details>
</div>   
   
<br>   
<div class="console_R"> R    
```{r eval=FALSE}
# Extraction of SNPs with low INFO:

r2_04_remove <- pvar[pvar$R2 < 0.4,]
r2_04_remove
```
</div>    
  <br>
```{r echo=FALSE}
r2_04_remove <- pvar[pvar$R2 < 0.4,]
knitr::kable(r2_04_remove)
```
<br>
These SNPs will be added to a .txt file called to_remove later, to be filtered in the last step of this QC.

<br>

## b) Minor allele frequency (MAF){#b_minor}

Minor Allele Frequency (MAF) indicates the rarity of a genetic variant within a population. Variants with a MAF greater than 5% are considered common, those with a MAF between 1% and 5% are categorized as low frequency, and variants with a MAF less than 1% are considered rare.

In PRS analyses, it's common practice to filter out SNPs with low frequency because they may not have enough statistical power to provide meaningful insights. In this case, we will apply a threshold of 0.005 directly to the Plink2 function using the *--maf* flag. This threshold helps ensure that only SNPs with a MAF greater than or equal to *0.005* are included in the analysis, focusing on more common variants for robust and reliable results.


## c) Linkage Disequilibrium (LD){#c_LD}

Linkage disequilibrium (LD) measures the connection between closely located genetic variants that often share inheritance patterns because of their proximity, leading to a genetic association within a population.

During the construction of a PRS, variants in high LD will have been identified and removed by methods such as clumping / pruning. This is done to reduce redundancy and bias in the PRS analysis, as it is desired that the markers used be as informative as possible without duplicating information.

In order to verify this, or apply more stringent thresholds, the PLINK 2 command **--indep-pairwise** can be used to prune the data, resulting in a subset of variants with LD below a specified threshold.
<br>

<div class="console_bash"> LINUX Terminal
```{bash eval = F }
# Pruning / clumping to remove highly correlated SNPs:
cd ./practical

plink2 \
    --pfile data/1_snps_extraction/raw_data \
    --indep-pairwise 200 1 0.3 \
    --out data/3_QC/LD
      
            ## "200" refers to the distance in kilobases (kb) between the SNPs
      ## "1" refers to the maximum number of SNPs that can be included in a clumping group.
      ## "0.3" is the correlation threshold (R^2) used to determine if two SNPs are "clumpable"
```
</div>
<br>

<center>
![](figures/3_LD.png){width=80%}
</center>
<br>

After applying this formula, two files are generated:
  
  - LD.prune.out -> Contains SNPs to be removed due to linkage disequilibrium.
  - LD.prune.in -> Contains SNPs that do not exhibit linkage disequilibrium.

<br>


<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> How many SNPs exhibit Linkage Disequilibrium?
    </summary>
    <br>
    Let's see whitch SNPs present a linkage desequilibrium:
    <br>
<div class="console_R"> R    
```{r}
ld_snps <- read.table("data/3_QC/LD.prune.out",header=F,sep="\t")
ld_snps <- ld_snps$V1
length(ld_snps) 

ld_snps
```

</div>    
  </details>
</div>

<br>


## d) Hardy-Weinberg Equilibrium (HWE){#hwe} 

Hardy-Weinberg Equilibrium (HWE) is a principle stating that allele and genotype frequencies should remain constant in a stable, unchanging population. Deviations from HWE may suggest genotyping errors, leading to the exclusion of such variants in analyses.

The PLINK 2 command **--hwe** filters out variants deviating from HWE using a specified p-value threshold.


HWE was previously tested in the GenRisk data; however, it is now confirmed using a threshold of 1e-6:

<div class="console_bash"> LINUX Terminal
```{bash eval = F }
plink2 \
    --pfile data/1_snps_extraction/raw_data \
    --hwe 1e-6 \
    --write-snplist \
    --out data/3_QC/HWE_QC
```
</div>
<br>

<center>
![](figures/3_HWE.png){width=80%}
</center>
<br>
No variant should be deleted fro HWE.
<br>


## Apply QC exclusions{#qc_exclu} 

All SNPs that have not passed QC, as well as ambiguous ones, are saved to a file called to_remove.txt and removed from the Target Data using PLINK2.

### to_remove.txt creation

In the PRS calculation function, Plink only accepts a list of SNPs to be excluded. Therefore, we need to combine the list of:

  - SNP extracted and not included in the list of interests. `1` SNP, save as multi_to_remove.txt
  - Ambiguous SNPs. `3` SNPs, save as exclrsIDs_ambiguous.txt
  - SNPs with low INFO. `2` SNPs, save as r2_04_remove (r object). 
  - LD SNPs. `2` SNPs, save as ld_snps (r object)
  
This combined list is saved in a file named "to_remove.txt."


<div class="console_R"> R 
```{r}
# The incorrect SNP extracted load.
multi_remove <-read.table("data/2_SNPs_alignament_check/multi_to_remove.txt", colClasses = c("character"))
colnames(multi_remove) <- c("CHROM", "ID", "REF", "ALT")
multi_remove
```
</div>
<br> 


<div class="console_R"> R 
```{r}
# The ID columns are selected
ambiguous_snps_ID <- ambiguous_snps$ID
r2_04_remove_ID <- r2_04_remove$ID
multi_remove_ID  <- multi_remove$ID
```
</div>
<br>

The various SNPs lists are cross-referenced to identify matches.
<br>
<div class="console_R"> R 
```{r}
table(ambiguous_snps_ID == multi_remove_ID)
```

```{r}
table(ambiguous_snps_ID %in% r2_04_remove_ID)
```

```{r}
table(multi_remove_ID %in% r2_04_remove_ID)
```

```{r}
table(ld_snps %in% multi_remove_ID)
```

```{r}
table(ld_snps %in% r2_04_remove_ID)


```

```{r}
table(ld_snps %in% ambiguous_snps_ID)
```
</div>
<br> 


<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> Finally, how many SNPs have failed QC and will be removed?
    </summary>
    <br>
There are `2` SNPs that present both LD and a low imputation quality score. So in total we have 6 SNPs that have not passed the QC and will be removed.
  </details>
</div>

<br>

<div class="console_R"> R
```{r}
# Union of the tables
to_remove <- unique(c(ambiguous_snps_ID,multi_remove_ID,r2_04_remove_ID,ld_snps ))
to_remove
```
</div>
<br>

<div class="console_R"> R
```{r eval=FALSE}
# Save
write.table(to_remove, "data/3_QC/to_remove.txt", quote = FALSE, row.names = FALSE, col.names = F)
```
</div>
<br> 


### Filtering of SNPs with PLINK2

The next step involves data filtering to exclude SNPs in the **to_remove.txt**. On the other hand, it is still pending to apply the filter based on Minor Allele Frequency (MAF) using the --maf flag.
<br>
<div class="console_bash"> LINUX Terminal
```{bash eval=F}

cd ./practical

#Scrip aplicat:
plink2 \
--pfile data/1_snps_extraction/raw_data \
--exclude data/3_QC/to_remove.txt \
--maf 0.005 \
--write-snplist \
--make-pgen \
--out data/3_QC/dataQC

```
</div>
<br>  
<center>
![](figures/3_qc_filt.png){width=80%}
</center>
<br>

The outputs of the command above are: 

* **dataQC.pgen, dataQC.psam, dataQC.pvar**: Data after SNP QC (excpet HWE) in PLINK 2 binary format
* **dataQC.snplist**: List of IDs of SNPs that passed QC with the specified thresholds (from `--write-snplist`)

<div class="question">
  <details>
    <summary><strong>**QUESTION** </strong> What is the total number of SNPs remaining?
    </summary>
    <br>
   `199` SNPs
   <br>
   
From the initial 205, the following have been removed: 

  -1 for being on the X sex chromosome 
  -3 for ambiguous 
  -2 for low imputation score 
  -0 for low MAF
  -2 (idem INFO) LD

  </details>
</div>

<br>


# STEP 4 - PRS calculation{#step4}

  - 1 Preparació score.txt
  - 2 PRS calculation
  - 3 PRS score rescaling

## 1 Preparació score.txt

Creating a file with 3 columns:
    -ID of the SNPs that have passed the QC
    -The RISK_ALLELE
    -Betas

Thus ensuring that the risk allele according to the beta value.

This process is carried out to ensure that the PRS are consistent and accurately reflect genetic risk. In some genetic analyses, beta values associated with a SNP can be positive or negative depending on their association with a particular disease or trait. By changing the sign of negative betas to make them positive, it ensures that all genetic contributions are positive. This makes it easier to interpret them in terms of cumulative genetic risk.


<br>

### Load data

It is necessary both the data of the SNPs of the target data and the beta values of the original list of the SNPs of interest. A series of modifications are made to match column names and data structure.

The ID in the target data has this structure: chr:position_ref_alt - e.x: 1:110365045_G_A.

In the case of the original SNPs list with beta data (representing the weight of each SNP in the trait under study), the structure is as follows: chr:position_other_risk, where the risk allele is determined by the sign of the beta value. In other words:

  - For SNP 1:22503282_G_C with a positive beta value, the risk allele is C.
  - For SNP 1:22503282_G_C with a negative beta value, the risk allele is G

<div class="console_R"> R
```{r}
# Load Info SNPs resultants del QC
snps_qc<-read.table("data/3_QC/dataQC.pvar")
colnames(snps_qc) <- c("CHROM",	"POS", 	"ID", "REF", "ALT", "FILTER", "INFO")

#Transform ID to: chr:position_all_1:all_2 format
#snps_qc$ID <- gsub("_",":",snps_qc$ID)

#Keep ID and ALT / RISK_ALLELE
names(snps_qc)[names(snps_qc) == "ALT"] <- "RISK_ALLELE"
names(snps_qc)[names(snps_qc) == "REF"] <- "OTHER_ALLELE"
snps_qc <- snps_qc[,c("ID", "RISK_ALLELE","OTHER_ALLELE" )]
```
```{r eval=FALSE}
head(snps_qc) 
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(head(snps_qc) )
```
<br>



From the data of the initial SNPs list we only save the ID and the beta value:

<div class="console_R"> R
```{r}
# Load beta values.
betas <- read_excel("data/resources/1_CRC_SNPs_list_205_Nature_2023.xlsx")

#Transform ID to: chr:position_all_1:all_2 format -> 1:110365045_A_G
names(betas)[names(betas) == "VARIANT"] <- "ID"
names(betas)[names(betas) == "BETA"] <- "RISK_SCORE"
#betas$ID <- gsub("_",":",betas$ID)
betas$ID <- gsub("/","_",betas$ID)

betas <- betas[,c(3,7)]
```
```{r eval=FALSE}
head(betas)
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(head(betas))
```
<br>

### Merge information

It is checked that beta values are available for all SNPs and the two tables are joined according to the IDs.

<div class="console_R"> R
```{r}
# Checking

table(snps_qc$ID %in% betas$ID)
```

```{r eval=FALSE}
# Merge 
score <- merge(snps_qc, betas, by = "ID", all.x = TRUE)
head(score)
```
</div>
<br>
```{r echo=FALSE}
score <- merge(snps_qc, betas, by = "ID", all.x = TRUE)
knitr::kable(head(score))
```
<br>



### setting all beta values to positive


Modification of the score_modif.txt list with the aim of setting all beta values to positive.

In cases where the beta value is negative:

  *1.- the risk alleles are exchanged - other
  *2.- The sign (- -> +) of the beta value is changed.

The results are saved in *score_final.txt*

<div class="console_R"> R
```{r eval=FALSE}
#Create new RISK_ALLELE column to be able to modify it according to the beta value
score$RISK_ALLELE_2 <- score$RISK_ALLELE
head(score)
```
</div>
<br>
```{r echo=FALSE}
score$RISK_ALLELE_2 <- score$RISK_ALLELE
knitr::kable(head(score))
```
<br>


<div class="console_R"> R
```{r}

#Change Risk_allele <-> Other_allele in the negative beta values cases:
for (i in 1:nrow(score)){
      
    # iterate over the column nº4 ("RISK_SCORE")  and check if <0
    if(score[i,4]<0){
           
        # replace the value with OTHER_ALLELE (column 3) in the new column RISK_ALLEL_2 (5)
        score[i,5]<- score[i,3]
        }
}

#Change beta value sign - to -> +
score$RISK_SCORE_2 <- as.numeric(gsub("-", "",score$RISK_SCORE ))


#Dalate some columns
score[,2:4] <- NULL

```
```{r eval=FALSE}
head(score)
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(head(score))
```
<br>

<div class="console_R"> R
```{r eval=FALSE}
#Save the new score doc as score_final.txt 
write.table(score,"data/4_PRS_calculation/score_final.txt", col.names = F, quote = F, row.names = F)

```
</div>
<br>



## 2 PRS calculation:

<div class="console_bash"> LINUX Terminal
```{bash eval=FALSE}
#PRS calculation 
cd ./practical

plink2 \
--pfile data/1_snps_extraction/raw_data \
--extract data/3_QC/dataQC.snplist \
--score data/4_PRS_calculation/score_final.txt no-mean-imputation \
--out data/4_PRS_calculation/PRS

```
</div>
<br>

<center>
![](figures/3_score.png){width=80%}
</center>

<br>
Result file:

  - *PRS.sscore*
  
  

## 3 PRS score rescaling

The SCORE_AVG values are initially in a very small range and are rescaled to larger values to enhance result interpretability. Using the scale function -> https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale
<br>

<div class="console_R"> R
```{r}
# Load results:
scores <- read.table("data/4_PRS_calculation/PRS.sscore")
colnames(scores)<- c("IID",	"NMISS_ALLELE_CT",	"ALLELE_DOSAGE_SUM",	"SCORE1_AVG")

#Rescale the scores
scores$SCORE1_AVG_scale <- scale(scores$SCORE1_AVG, center = T, scale = T)
```
```{r eval=FALSE}
head(scores)
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(head(scores))
```
<br> 



<div class="console_R"> R
```{r echo=F}
# Save final scores:
write.table(scores,"data/5_PRS_results/PRS_final.txt", col.names = T, quote = F, row.names = F)
```
</div>
<br>


# STEP 5 - PRS results{#step5}

Then and as a last step, the results are reviewed and plotted to verify that the calculated PRS really discriminates between CRC cases and controls.

- [1 The calculated scores are combined with the sample phenotypes (case or control).](#pheno)
- [2 A t.test is performed between cases and controls.](#ttest)
- [3 The scores are plotted based on the case-control status.](#plot)
    - [Histogram](#histo)
    - [Density plot](#dens)
    - [Boxplot](#boxplot)
    - [qqplot](#qqplot)


## Assign the phenotype{#pheno}

**Add phenotypes of interest**

The phenotypic data of the target data are loaded.

<br>
<div class="console_R"> R
```{r} 
# Samples to extract
samples<-read.table("data/resources/GenRisk_ImputedData_CRC_Samples.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t")

```
```{r eval=FALSE}
head(samples)
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(head(samples))
```
<br> 


<div class="console_R"> R
```{r}
table(samples$tipo_cancer)
```
</div>
<br>


**merge scores + phenotypes**

Use of all CRC and all Controls selected in the 0_Data_sample_preparation.

<br>
<div class="console_R"> R
```{r}
#Unir columnes samples i PRS.score per les ID de pacients
scores_samples<-merge(scores,samples,by.x="IID",by.y="ID",all=FALSE)
```
```{r eval=FALSE}
head(scores_samples)
```
</div>
<br>
```{r echo=FALSE}
knitr::kable(head(scores_samples))
```
<br> 
</div>
<br>



## Statistics{#ttest}

A t.test is performed between cases and controls to check if there are differences between the calculated scores of these two groups.

<div class="console_R"> R
```{r}
# plots
ttest<-t.test(scores_samples$SCORE1_AVG_scale~scores_samples$tipo_cancer)
tpval<- t.test(scores_samples$SCORE1_AVG_scale~scores_samples$tipo_cancer)$p.value
tpval  
```
</div>
<br>




## PRS Plots{#plot}

### Histogram{#histo}

<div class="console_R"> R
```{r}
# Histogram:
histo <- ggplot(scores_samples, aes(x = SCORE1_AVG_scale))+ 
  geom_histogram(aes(y=..density.. ,fill = tipo_cancer, color = tipo_cancer), alpha = 0.5, position = "identity") +
  scale_fill_manual( values = c("steelblue4", "gray87")) +
   scale_color_manual(values = c("steelblue4", "gray50"))+
   theme_classic()+
  xlab("Polygenic risk score (PRS)") + 
  ylab("Density")+
 
  #labs(fill="xyz")+
   labs(title = "Colorectal cancer", subtitle = "p <0.0001 ")+
   theme(text = element_text(size = 16),
         legend.position = "bottom") +
theme(legend.title=element_blank())
```
```{r eval=FALSE}
histo
```
</div>
<br>
```{r echo=FALSE}
histo
```
<br>

### Density plot{#dens}


<div class="console_R"> R
```{r}
# Density plot
density <- ggplot(scores_samples, aes(x = SCORE1_AVG_scale, color = tipo_cancer))+ 
  geom_density()+
  scale_color_manual(values=c("#99B1C4", "gray50"))+
   labs(title = "Risk score distribution",
              #subtitle = "Plot of length by dose",
              caption = paste0("t-test pval=",tpval))+
   theme_minimal()+
  theme(text = element_text(size = 20)) 

```
```{r eval=FALSE}
density
```
</div>
<br>
```{r echo=FALSE}
density
```
<br>

### Boxplot{#boxplot}

<div class="console_R"> R
```{r}
# Boxplot
boxplot <- ggplot(scores_samples, aes(x=tipo_cancer, y=SCORE1_AVG_scale, fill=tipo_cancer)) +
  geom_boxplot()+
  labs(x="", y = "Risk Score")+
  scale_x_discrete(limits=c("Control", "Colorectal"))+
  scale_fill_manual(values=c("#99B1C4", "gray87"))+
  theme_classic()+
  theme(text = element_text(size = 20), legend.position = "none") 
```
```{r eval=FALSE}
boxplot
```
</div>
<br>
```{r echo=FALSE}
boxplot
```
<br>

### qqplot{#qqplot}

<div class="console_R"> R
```{r eval= FALSE}
# qqplot
qwe1<-qqnorm(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer =="Control"],plot.it=FALSE)
qwe2<-qqnorm(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer=="Colorectal"],plot.it=FALSE)

plot(qwe1$x,qwe1$y,pch=19,las=1,main="",col="darkgrey",xlab="Theoretical Quantiles",ylab="Sample Quantiles")
qqline(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer== "Control"],col="darkgrey",lwd=2)
points(qwe2$x,qwe2$y,pch=19,col="#99B1C4")
qqline(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer== "Colorectal"],col="#99B1C4",lwd=2)
title("Risk score Q-Q Plot",sub=paste0("t-test pval=",tpval))

```
</div>
<br>
```{r echo=FALSE}
qwe1<-qqnorm(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer =="Control"],plot.it=FALSE)
qwe2<-qqnorm(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer=="Colorectal"],plot.it=FALSE)

plot(qwe1$x,qwe1$y,pch=19,las=1,main="",col="darkgrey",xlab="Theoretical Quantiles",ylab="Sample Quantiles")
qqline(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer== "Control"],col="darkgrey",lwd=2)
points(qwe2$x,qwe2$y,pch=19,col="#99B1C4")
qqline(scores_samples$SCORE1_AVG_scale[scores_samples$tipo_cancer== "Colorectal"],col="#99B1C4",lwd=2)
title("Risk score Q-Q Plot",sub=paste0("t-test pval=",tpval))
```
<br>

# Extra information

## Liftover {#liftover}

**Transform data from a genome version to another genome version**

Suppose our data is in hg19 and we want to impute using TOPMed panel as reference hg19 to hg38
https://github.com/sritchie73/liftOverPlink

Download the chain file that allows the mass conversion of coordinates from one assembly to another.
http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/


```{bash eval = FALSE}
liftOverPlink.py 
-m plinkFile.map 
-p plinkFile.ped 
-o plinkFile_lifted 
-c hg19ToHg38.over.chain.gz 
```


or see https://genviz.org/module-01-intro/0001/06/02/liftoverTools/ 
